---
title: "Intro to Linear Regression"
author: "Kirsten Hodgson"
date: "11/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(palmerpenguins)
library(ggpubr)
library(broom)
```

## Rank-based tests (Mann-Whitney U)

1. Create two "pseudorandom" sample vectors.

```{r}
set.seed(1414)
gp_1 <- sample.int(20, size = 15, replace = TRUE)

set.seed(1424)
gp_2 <- sample.int(30, size = 15, replace = TRUE)
```

2. Look at the data.

```{r}
hist(gp_1)
hist(gp_2) #May decide on rank-based test bc not clearly normally distributed, small sample size (n=15), or because we think that medians are a more valuable metric of comparison for these data
```

3. Run Mann-Whitney U.

```{r}
my_mwu <- wilcox.test(gp_1, gp_2)
```

## Simple linear regression

1. Data exploration

```{r}
ggplot(data = penguins, aes(x = flipper_length_mm, y = body_mass_g)) +
  geom_point()
```

- Does it look like a linear relationship makes sense?
- Do we have any concerns about modeling as a linear relationship?
- Any notable outliers?
- Initial thoughts about homoscedasticity? (Will explore more later)

Looks like an overall linear relationship makes sense.

2. Model the data.

*Note that we haven't checked all assumptions yet because many are based on residuals so must be checked after we make the model*

```{r}
#Linear model, stored as penguin_lm:
penguin_lm <- lm(body_mass_g ~ flipper_length_mm, data = penguins)

#Return the COMPLETE overview:
summary(penguin_lm)
```

3. Access model outputs.

- The slope is 49.69 g/mm
- The y-intercept is -5780.83 g
- The full equation is mass = 49.69*(flipper length) + (-5780.83)

**But** the summary output is a bit of a mess to try to get all the statistical information from. So use broom::tidy() function to get the model outputs in nice data frame format:

```{r}
penguin_lm_tidy <- broom::tidy(penguin_lm)
```

This puts the model outputs in a tidy table, which we can use to refer to outputs later on:

```{r}
#Get the intercept:
penguin_int <- penguin_lm_tidy$estimate[1]
penguin_int
```

```{r}
#Then to get the flipper length coefficient:
penguin_coef <- penguin_lm_tidy$estimate[2]
penguin_coef
```

We can access other model information (like degrees of freedom, F statistic, p-value) more easily using broom::glance().

```{r}
#Metrics at a glance:
penguin_lm_out <- broom::glance(penguin_lm)
penguin_lm_out
```

We can use these functions to write a statement about the model that will **automatically update** if anything about the model changes!

"Simple linear regression was used to explore the relationship between penguin flipper length (mm) and body mass (g) across all three penguin species, and including both male and female penguins. A significant regression model was found ($\beta$ = `r round(penguin_coef, 3)`, F(`r penguin_lm_out$df`, `r penguin_lm_out$df.residual`) = `r round(penguin_lm_out$statistic,1)`, p < 0.001) with an R^2^ of `r round(penguin_lm_out$r.squared, 3)`."

While this might seem *really* tedious to write out, it's worth it because the values will be automatically updated when the model is updated - yay for reproducibility and avoiding human error! Also note that using p < 0.001 is somewhat standard when p-value is very small.

4. Explore model assumptions.

We need to explore our assumptions for linear regression:

- Linearly related variables (CHECK - already looked and thought hard)
- Normally distributed *residuals*
- Homoscedasticity (constant residuals variance)
- iid residuals (no serial correlation) - more often a concern in time series data

Using the plot() function on the model will automatically create four useful visualizations to consider assumptions.

```{r}
plot(penguin_lm)
```

4 plots show up. What do they show?

- **The first one:** fitted values vs. residuals
- **The second one:** QQ-plot for residuals
- **The third one:** another way of looking at fitted vs. residuals (these are just standardized residuals, but you can interpret it the same way)
- **The fourth one:** Cook's distance, a measure of "influence" or "leverage" that individual points have on the model - often considered a way to explore outliers

Graphs 1 & 3 are useful for thinking about homoscedasticity; graph 2 (QQ-plot) helps us consider normality of residuals; graph 4 reveals the Cook's distance (a measure of how much leverage any single observation has on the model).

5. Visualize the model.

Because we've explored the assumptions and have concluded that linear regression is a valid tool to describe the relationship between flipper length and body mass, let's look at the model.

- Use `geom_smooth(method = "lm")` to add a linear model to an existing scatterplot
- Use `stat_cor()` and/or `stat_regline_equation()` to add equation information directly to the plot panel, at an x- and y-position that you specify (and yes, you can mess with the digits and appearance here)

```{r}
ggplot(data = penguins, aes(x = flipper_length_mm, y = body_mass_g)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm",
              color = "red",
              size = 0.5,
              fill = "gray10",
              alpha = 0.5) +
  theme_light() +
  ggpubr::stat_regline_equation(label.x = 180, label.y = 5700)
```

6. Find Pearson's *r* for correlation.

R^2^ tells us how much of the variance in the dependent variable is explained by the model.

We might also want to explore the strength of the correlation (degree of relationship) between two variables which, for two linearly related continuous variables, can be expressed using Pearson's *r*.

Pearson's *r* ranges in value from -1 (perfectly negatively correlated - as one variable increases the other decreases) to 1 (perfectly positively correlated - as one variable increases the other increases). A correlation of 0 means that there is no degree of relationship between the two variables.

Typical guidelines for this (but with wiggle room):

- *r* = 0: no correlation
- *r* < |0.3|: weak correlation
- *r* between |0.3| and |0.7|: moderate correlation
- *r* > |0.7|: strong correlation

We'll use the `cor.test()` function, adding the two vectors (`flipper_length_mm` and `body_mass_g`) as the arguments. The function reports the Pearson's *r* value, and performs a hypothesis test with null hypothesis that the correlation = 0.

```{r}
penguins_cor <- cor.test(penguins$flipper_length_mm, penguins$body_mass_g)
penguins_cor
```

The cor value is >0.8, so there is a strong positive correlation between penguin flipper length and body mass (*r* = `r round(penguins_cor$estimate,2)`, t(`r penguins_cor$parameter`) = `r round(penguins_cor$statistic, 2)`, p < 0.001)

**Note**: Once you have a "template" statement, you can just replace `penguins_cor` here with whatever your correlation analysis is stored as! You don't need to recreate the wheel every time! 

## END LAB - CONGRATULATIONS!